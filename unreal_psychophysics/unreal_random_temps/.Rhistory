ll.null<-logistic$null.deviance/-2
ll.proposed<-logistic$deviance/-2
#McFadden's R squared
rsqr<-(ll.null-ll.proposed)/ll.null
#pvalue of R squared
rsqr.pval<-1-pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
pseudo_r<-rsqr
stim_x<-samples$stim_x
y<-samples$y
#1.get the fitted probabilities and the original y data
predicted.data<-data.frame(probability.of.detection=logistic$fitted.values,detection=y,stimuli=stim_x)
#2.order the data frame
predicted.data<-predicted.data[order(predicted.data$probability.of.detection,decreasing = FALSE),]
# predicted.data$stimuli<-predicted.data$stimuli
detection_rates<-aggregate(detection ~ stimuli, data = predicted.data, mean)
#make sure range is at least 0% detection to 99%
prediction.flag<-FALSE
current_max<-0
h<-0
while (prediction.flag==FALSE){
#create range of stim values to predict odds for
range_x<-range(0.0001,stim_x[1]+h) #this needs to extend to the lowest possible value in x or we wont get the 0.25 thre
#set prediction limits
min_range<-min(range_x)
max_range<-max(range_x)
step_size<-(max_range-min_range)/100000
#create a vector from range
data.to.predict<-data.frame(stim_x=seq(min_range,max_range,step_size))
#get the predictions for this range of x values from the glm
new.predictions<-predict(logistic, data.to.predict,type="response")
modeled_samples<-data.frame(stim_x=data.to.predict,y=new.predictions)
new_max<-max(modeled_samples$y)
#make sure we got at least to 99% and that the max % can actually reach 99
if (new_max<0.99 && current_max<new_max){
current_max<-max(modeled_samples$y)
h<-h+1
} else {prediction.flag<-TRUE}
}
#now we have a range of predicted values between 0% and whatever max value we found for 99%
#we should now shorten this range as much as we can for effective plotting
unique_data<-table(predicted.data$stimuli)/length(predicted.data$stimuli)
unique_data<-as.data.frame(unique_data)
colnames(unique_data)[1]<-"stimuli"
colnames(unique_data)[2]<-"prop" #proportion presented out of all stims
#column bind unique_data and sub_predicted.data$probability...
unique_data<-cbind(unique_data,detection_rates$detection)
colnames(unique_data)[3]<-"prob" #likelihood of detection based on model
unique_data$stimuli<-as.character(unique_data$stimuli)
unique_data$stimuli<-as.numeric(unique_data$stimuli)
sub_color<-"black"
#conditions for accepting this fit
sample_zone<-sum(between(logistic$fitted.values,left = 0.15,right = 0.85))
if (pseudo_r<0.2 || sample_zone<1){
sub_color<-"red"
#gather the conditions that need retaking
retake_list<-append(retake_list,condition_df$ConditionName[1])
}
my_thresholds<-c()
my_thresholds[1]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.25)==min(abs(modeled_samples$y-0.25)))]
my_thresholds[2]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.5)==min(abs(modeled_samples$y-0.5)))]
my_thresholds[3]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.75)==min(abs(modeled_samples$y-0.75)))]
my_thresholds[4]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.95)==min(abs(modeled_samples$y-0.95)))]
#check we really have 4 thresholds and if not inform the user
if (length(unique(my_thresholds))!=4){
sub_color<-"red"
cat(name,':not enough thresholds','\n')
}
#make the graph nicer by cutting the left tail where the data is redundant
#special end of the vector value (2.220446e-16 is 'zero' in Rstudio)
#we are finding the maximal and minimal stim values that is predicted to be found 0% or 100% of trials
end_of_vector<-max(modeled_samples$stim_x[which(abs(modeled_samples$y-2.220446e-16)==min(abs(modeled_samples$y-2.220446e-16)))])
start_of_vector<-min(modeled_samples$stim_x[which(abs(modeled_samples$y-0.99)==min(abs(modeled_samples$y-0.99)))])
#the predicted probability for detecting the weakest stim value
end_of_stims<-min(samples$stim_x)
#
start_of_stims<-max(samples$stim_x)
#if the last stim has detection prob=0 or was lower than the 25% threshold then make it the end of the plot
if (unique_data[1,'prob']==0 || unique_data[1,'stimuli']<my_thresholds[1]){end_of_vector<-end_of_stims}
#if the 25% threshold is lower than the smallest stim value, then stop plotting after the 25% threshold
if (unique_data[1,'stimuli']>my_thresholds[1]){end_of_vector<-my_thresholds[1]}
#
first_sampled<-length(unique_data$stimuli)
#if the first stimuli has a 100% detection pred, then start plotting from there
if (unique_data[first_sampled,'prob']==1){start_of_vector<-start_of_stims}
#if the first stimuli is smaller than the stim predicted for 95% detection, then start the plot after the 95% mark
if (unique_data[first_sampled,'prob']>my_thresholds[4]){start_of_vector<-my_thresholds[4]}
#limit range of modeld responses between 95%-0%
modeled_samples<-modeled_samples[modeled_samples$stim_x>=end_of_vector & modeled_samples$stim_x<=start_of_vector,]
prob<-c(0.25,0.5,0.75,0.95)
single_fit<-data.frame(my_thresholds,prob)
plot_subtitle<-paste('[',as.character(round(my_thresholds[1],2)),', ',as.character(round(my_thresholds[2],2)),', ',as.character(round(my_thresholds[3],2)),', ',as.character(round(my_thresholds[4],2)),'] ',"R:",as.character(round(pseudo_r,2)))
plot_list[[i]]<-ggplot(modeled_samples,aes(x=stim_x,y=y))+
ggtitle(name)+xlab("stim")+theme(plot.title=element_text(face="bold",size=9,hjust=0.5),plot.subtitle = element_text(face="bold",color=sub_color,size=8,hjust=0.5),axis.title.y = element_text(size=8),axis.text.y = element_text(size=6,face="bold",color="black"),axis.text.x = element_text(size=6,face="bold",color="black"),axis.title.x = element_blank())+labs(subtitle=plot_subtitle)+
geom_smooth(method = glm, method.args=list(family = binomial), se=TRUE)+
geom_point(unique_data,mapping=aes(x=stimuli,y=prob,size=prop,alpha=0.2))+
guides(size = FALSE,alpha=FALSE,color=FALSE)+
#xlab("Stimuli")+
ylab("Prob")+theme(plot.subtitle = element_text())+
geom_vline(xintercept=my_thresholds[1],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[2],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[3],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[4],color="gray",linetype="dashed")
#gather the information into a summary file for saving to results folder
single_fit$Condition<-name
#collect pseudo R's
single_fit$Mcf_pR<-pseudo_r
single_fit$p.val<-rsqr.pval
#define max staircase value for thresholdfix()
if (condition_df$StairCaseValue[1]>0){
single_fit$max_strength<-max(condition_df$StairCaseValue)
} else if (condition_df$StairCaseValue[1]<0){
single_fit$max_strength<-min(condition_df$StairCaseValue)
}
x_thresholds<-rbind(x_thresholds,single_fit)
}
fit_plot_grid<-cowplot::plot_grid(plotlist = plot_list,nrow=3,ncol=3,rel_heights = c(1,1))
fit_plot_grid
i<-0
##fit conditions
for (name in ConditionName_vec){
condition_df<-df[df$ConditionName==name,]
cond_name<-name;
i<-i+1
#define predictor and predicted vars
stim_x<-condition_df$log_percent
y<-condition_df$QuestionResult
samples<-data.frame(stim_x,y)
samples$stim_x<-round(samples$stim_x,6)
#creating glm for condition
logistic <- glm(y~stim_x, data=samples ,family=binomial(logit))
#compute loglikelihoods
ll.null<-logistic$null.deviance/-2
ll.proposed<-logistic$deviance/-2
#McFadden's R squared
rsqr<-(ll.null-ll.proposed)/ll.null
#pvalue of R squared
rsqr.pval<-1-pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
pseudo_r<-rsqr
stim_x<-samples$stim_x
y<-samples$y
#1.get the fitted probabilities and the original y data
predicted.data<-data.frame(probability.of.detection=logistic$fitted.values,detection=y,stimuli=stim_x)
#2.order the data frame
predicted.data<-predicted.data[order(predicted.data$probability.of.detection,decreasing = FALSE),]
# predicted.data$stimuli<-predicted.data$stimuli
detection_rates<-aggregate(detection ~ stimuli, data = predicted.data, mean)
#make sure range is at least 0% detection to 99%
prediction.flag<-FALSE
current_max<-0
h<-0
while (prediction.flag==FALSE){
#create range of stim values to predict odds for
range_x<-range(0.0001,stim_x[1]+h) #this needs to extend to the lowest possible value in x or we wont get the 0.25 thre
#set prediction limits
min_range<-min(range_x)
max_range<-max(range_x)
step_size<-(max_range-min_range)/100000
#create a vector from range
data.to.predict<-data.frame(stim_x=seq(min_range,max_range,step_size))
#get the predictions for this range of x values from the glm
new.predictions<-predict(logistic, data.to.predict,type="response")
modeled_samples<-data.frame(stim_x=data.to.predict,y=new.predictions)
new_max<-max(modeled_samples$y)
#make sure we got at least to 99% and that the max % can actually reach 99
if (new_max<0.99 && current_max<new_max){
current_max<-max(modeled_samples$y)
h<-h+1
} else {prediction.flag<-TRUE}
}
#now we have a range of predicted values between 0% and whatever max value we found for 99%
#we should now shorten this range as much as we can for effective plotting
unique_data<-table(predicted.data$stimuli)/length(predicted.data$stimuli)
unique_data<-as.data.frame(unique_data)
colnames(unique_data)[1]<-"stimuli"
colnames(unique_data)[2]<-"prop" #proportion presented out of all stims
#column bind unique_data and sub_predicted.data$probability...
unique_data<-cbind(unique_data,detection_rates$detection)
colnames(unique_data)[3]<-"prob" #likelihood of detection based on model
unique_data$stimuli<-as.character(unique_data$stimuli)
unique_data$stimuli<-as.numeric(unique_data$stimuli)
sub_color<-"black"
#conditions for accepting this fit
sample_zone<-sum(between(logistic$fitted.values,left = 0.15,right = 0.85))
if (pseudo_r<0.2 || sample_zone<1){
sub_color<-"red"
#gather the conditions that need retaking
retake_list<-append(retake_list,condition_df$ConditionName[1])
}
my_thresholds<-c()
my_thresholds[1]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.25)==min(abs(modeled_samples$y-0.25)))]
my_thresholds[2]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.5)==min(abs(modeled_samples$y-0.5)))]
my_thresholds[3]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.75)==min(abs(modeled_samples$y-0.75)))]
my_thresholds[4]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.95)==min(abs(modeled_samples$y-0.95)))]
#check we really have 4 thresholds and if not inform the user
if (length(unique(my_thresholds))!=4){
sub_color<-"red"
cat(name,':not enough thresholds','\n')
}
#make the graph nicer by cutting the left tail where the data is redundant
#special end of the vector value (2.220446e-16 is 'zero' in Rstudio)
#we are finding the maximal and minimal stim values that is predicted to be found 0% or 100% of trials
end_of_vector<-max(modeled_samples$stim_x[which(abs(modeled_samples$y-2.220446e-16)==min(abs(modeled_samples$y-2.220446e-16)))])
start_of_vector<-min(modeled_samples$stim_x[which(abs(modeled_samples$y-0.99)==min(abs(modeled_samples$y-0.99)))])
#the predicted probability for detecting the weakest stim value
end_of_stims<-min(samples$stim_x)
#
start_of_stims<-max(samples$stim_x)
#if the last stim has detection prob=0 or was lower than the 25% threshold then make it the end of the plot
if (unique_data[1,'prob']==0 || unique_data[1,'stimuli']<my_thresholds[1]){end_of_vector<-end_of_stims}
#if the 25% threshold is lower than the smallest stim value, then stop plotting after the 25% threshold
if (unique_data[1,'stimuli']>my_thresholds[1]){end_of_vector<-my_thresholds[1]}
#
first_sampled<-length(unique_data$stimuli)
#if the first stimuli has a 100% detection pred, then start plotting from there
if (unique_data[first_sampled,'prob']==1){start_of_vector<-start_of_stims}
#if the first stimuli is smaller than the stim predicted for 95% detection, then start the plot after the 95% mark
if (unique_data[first_sampled,'prob']>my_thresholds[4]){start_of_vector<-my_thresholds[4]}
#limit range of modeld responses between 95%-0%
modeled_samples<-modeled_samples[modeled_samples$stim_x>=end_of_vector & modeled_samples$stim_x<=start_of_vector,]
prob<-c(0.25,0.5,0.75,0.95)
single_fit<-data.frame(my_thresholds,prob)
plot_subtitle<-paste('[',as.character(round(my_thresholds[1],2)),',',as.character(round(my_thresholds[2],2)),',',as.character(round(my_thresholds[3],2)),',',as.character(round(my_thresholds[4],2)),']',"R:",as.character(round(pseudo_r,2)))
plot_list[[i]]<-ggplot(modeled_samples,aes(x=stim_x,y=y))+
ggtitle(name)+xlab("stim")+theme(plot.title=element_text(face="bold",size=9,hjust=0.5),plot.subtitle = element_text(face="bold",color=sub_color,size=8,hjust=0.5),axis.title.y = element_text(size=8),axis.text.y = element_text(size=6,face="bold",color="black"),axis.text.x = element_text(size=6,face="bold",color="black"),axis.title.x = element_blank())+labs(subtitle=plot_subtitle)+
geom_smooth(method = glm, method.args=list(family = binomial), se=TRUE)+
geom_point(unique_data,mapping=aes(x=stimuli,y=prob,size=prop,alpha=0.2))+
guides(size = FALSE,alpha=FALSE,color=FALSE)+
#xlab("Stimuli")+
ylab("Prob")+theme(plot.subtitle = element_text())+
geom_vline(xintercept=my_thresholds[1],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[2],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[3],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[4],color="gray",linetype="dashed")
#gather the information into a summary file for saving to results folder
single_fit$Condition<-name
#collect pseudo R's
single_fit$Mcf_pR<-pseudo_r
single_fit$p.val<-rsqr.pval
#define max staircase value for thresholdfix()
if (condition_df$StairCaseValue[1]>0){
single_fit$max_strength<-max(condition_df$StairCaseValue)
} else if (condition_df$StairCaseValue[1]<0){
single_fit$max_strength<-min(condition_df$StairCaseValue)
}
x_thresholds<-rbind(x_thresholds,single_fit)
}
fit_plot_grid<-cowplot::plot_grid(plotlist = plot_list,nrow=3,ncol=3,rel_heights = c(1,1))
fit_plot_grid
i<-0
##fit conditions
for (name in ConditionName_vec){
condition_df<-df[df$ConditionName==name,]
cond_name<-name;
i<-i+1
#define predictor and predicted vars
stim_x<-condition_df$log_percent
y<-condition_df$QuestionResult
samples<-data.frame(stim_x,y)
samples$stim_x<-round(samples$stim_x,6)
#creating glm for condition
logistic <- glm(y~stim_x, data=samples ,family=binomial(logit))
#compute loglikelihoods
ll.null<-logistic$null.deviance/-2
ll.proposed<-logistic$deviance/-2
#McFadden's R squared
rsqr<-(ll.null-ll.proposed)/ll.null
#pvalue of R squared
rsqr.pval<-1-pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))
pseudo_r<-rsqr
stim_x<-samples$stim_x
y<-samples$y
#1.get the fitted probabilities and the original y data
predicted.data<-data.frame(probability.of.detection=logistic$fitted.values,detection=y,stimuli=stim_x)
#2.order the data frame
predicted.data<-predicted.data[order(predicted.data$probability.of.detection,decreasing = FALSE),]
# predicted.data$stimuli<-predicted.data$stimuli
detection_rates<-aggregate(detection ~ stimuli, data = predicted.data, mean)
#make sure range is at least 0% detection to 99%
prediction.flag<-FALSE
current_max<-0
h<-0
while (prediction.flag==FALSE){
#create range of stim values to predict odds for
range_x<-range(0.0001,stim_x[1]+h) #this needs to extend to the lowest possible value in x or we wont get the 0.25 thre
#set prediction limits
min_range<-min(range_x)
max_range<-max(range_x)
step_size<-(max_range-min_range)/100000
#create a vector from range
data.to.predict<-data.frame(stim_x=seq(min_range,max_range,step_size))
#get the predictions for this range of x values from the glm
new.predictions<-predict(logistic, data.to.predict,type="response")
modeled_samples<-data.frame(stim_x=data.to.predict,y=new.predictions)
new_max<-max(modeled_samples$y)
#make sure we got at least to 99% and that the max % can actually reach 99
if (new_max<0.99 && current_max<new_max){
current_max<-max(modeled_samples$y)
h<-h+1
} else {prediction.flag<-TRUE}
}
#now we have a range of predicted values between 0% and whatever max value we found for 99%
#we should now shorten this range as much as we can for effective plotting
unique_data<-table(predicted.data$stimuli)/length(predicted.data$stimuli)
unique_data<-as.data.frame(unique_data)
colnames(unique_data)[1]<-"stimuli"
colnames(unique_data)[2]<-"prop" #proportion presented out of all stims
#column bind unique_data and sub_predicted.data$probability...
unique_data<-cbind(unique_data,detection_rates$detection)
colnames(unique_data)[3]<-"prob" #likelihood of detection based on model
unique_data$stimuli<-as.character(unique_data$stimuli)
unique_data$stimuli<-as.numeric(unique_data$stimuli)
sub_color<-"black"
#conditions for accepting this fit
sample_zone<-sum(between(logistic$fitted.values,left = 0.15,right = 0.85))
if (pseudo_r<0.2 || sample_zone<1){
sub_color<-"red"
#gather the conditions that need retaking
retake_list<-append(retake_list,condition_df$ConditionName[1])
}
my_thresholds<-c()
my_thresholds[1]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.25)==min(abs(modeled_samples$y-0.25)))]
my_thresholds[2]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.5)==min(abs(modeled_samples$y-0.5)))]
my_thresholds[3]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.75)==min(abs(modeled_samples$y-0.75)))]
my_thresholds[4]<-modeled_samples$stim_x[which(abs(modeled_samples$y-0.95)==min(abs(modeled_samples$y-0.95)))]
#check we really have 4 thresholds and if not inform the user
if (length(unique(my_thresholds))!=4){
sub_color<-"red"
cat(name,':not enough thresholds','\n')
}
#make the graph nicer by cutting the left tail where the data is redundant
#special end of the vector value (2.220446e-16 is 'zero' in Rstudio)
#we are finding the maximal and minimal stim values that is predicted to be found 0% or 100% of trials
end_of_vector<-max(modeled_samples$stim_x[which(abs(modeled_samples$y-2.220446e-16)==min(abs(modeled_samples$y-2.220446e-16)))])
start_of_vector<-min(modeled_samples$stim_x[which(abs(modeled_samples$y-0.99)==min(abs(modeled_samples$y-0.99)))])
#the predicted probability for detecting the weakest stim value
end_of_stims<-min(samples$stim_x)
#
start_of_stims<-max(samples$stim_x)
#if the last stim has detection prob=0 or was lower than the 25% threshold then make it the end of the plot
if (unique_data[1,'prob']==0 || unique_data[1,'stimuli']<my_thresholds[1]){end_of_vector<-end_of_stims}
#if the 25% threshold is lower than the smallest stim value, then stop plotting after the 25% threshold
if (unique_data[1,'stimuli']>my_thresholds[1]){end_of_vector<-my_thresholds[1]}
#
first_sampled<-length(unique_data$stimuli)
#if the first stimuli has a 100% detection pred, then start plotting from there
if (unique_data[first_sampled,'prob']==1){start_of_vector<-start_of_stims}
#if the first stimuli is smaller than the stim predicted for 95% detection, then start the plot after the 95% mark
if (unique_data[first_sampled,'prob']>my_thresholds[4]){start_of_vector<-my_thresholds[4]}
#limit range of modeld responses between 95%-0%
modeled_samples<-modeled_samples[modeled_samples$stim_x>=end_of_vector & modeled_samples$stim_x<=start_of_vector,]
prob<-c(0.25,0.5,0.75,0.95)
single_fit<-data.frame(my_thresholds,prob)
plot_subtitle<-paste('[',as.character(round(my_thresholds[1],2)),',',as.character(round(my_thresholds[2],2)),',',as.character(round(my_thresholds[3],2)),',',as.character(round(my_thresholds[4],2)),']','\n',"R:",as.character(round(pseudo_r,2)))
plot_list[[i]]<-ggplot(modeled_samples,aes(x=stim_x,y=y))+
ggtitle(name)+xlab("stim")+theme(plot.title=element_text(size=9,hjust=0.5),plot.subtitle = element_text(color=sub_color,size=8,hjust=0.5),axis.title.y = element_text(size=8),axis.text.y = element_text(size=6,face="bold",color="black"),axis.text.x = element_text(size=6,face="bold",color="black"),axis.title.x = element_blank())+labs(subtitle=plot_subtitle)+
geom_smooth(method = glm, method.args=list(family = binomial), se=TRUE)+
geom_point(unique_data,mapping=aes(x=stimuli,y=prob,size=prop,alpha=0.2))+
guides(size = FALSE,alpha=FALSE,color=FALSE)+
#xlab("Stimuli")+
ylab("Prob")+theme(plot.subtitle = element_text())+
geom_vline(xintercept=my_thresholds[1],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[2],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[3],color="gray",linetype="dashed")+
geom_vline(xintercept=my_thresholds[4],color="gray",linetype="dashed")
#gather the information into a summary file for saving to results folder
single_fit$Condition<-name
#collect pseudo R's
single_fit$Mcf_pR<-pseudo_r
single_fit$p.val<-rsqr.pval
#define max staircase value for thresholdfix()
if (condition_df$StairCaseValue[1]>0){
single_fit$max_strength<-max(condition_df$StairCaseValue)
} else if (condition_df$StairCaseValue[1]<0){
single_fit$max_strength<-min(condition_df$StairCaseValue)
}
x_thresholds<-rbind(x_thresholds,single_fit)
}
fit_plot_grid<-cowplot::plot_grid(plotlist = plot_list,nrow=3,ncol=3,rel_heights = c(1,1))
fit_plot_grid
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/unreal_glm_GD_no_rounding_version_8.12.22.R', echo=TRUE)
save(unreal_glm, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\unreal_glm.rda')
NA!=NA
if(NA!=NA){cat('no')}
x<-NA
if(x==NA){cat('yes')}
x
x!=NA
x==NA
is.na(x)
if(x==NA || !is.na(x)){cat('yes')}
!is.na(x)
if(x==NA | !is.na(x)){cat('yes')}
round(NA,3)
x<-replace(x,is.na(x),0)
x
x<-NA
x<-replace(x,is.na(x),0)
x
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/unreal_psy_function_16.11.22.R', echo=TRUE)
save(unreal_psy, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\unreal_psy.rda')
2/100
1/100
2/100/2
2/100/2
3/100
3/100/3
4.615/100000
expm1(d.g15e-05)
expm1(4.615e-05)
expm1(4.615/100000)
expm1(4)
expm1(4.6)
expm1(4.61)
expm1(4.615)
expm1(4.6151)
expm1(4.61512)
expm1(4.61515)
expm1(4.61514)
expm1(4.61513)
expm1(4.61512)
expm1(4.615121)
4.615121/100000
5/100000
0.00005
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/unreal_glm_GD_no_rounding_version_8.12.22.R', echo=TRUE)
save(unreal_glm, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\unreal_glm.rda')
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/unreal_psy_function_16.11.22.R', echo=TRUE)
save(unreal_psy, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\unreal_psy.rda')
?glob2rx
list<-list.files(pattern="repeat", full.names=TRUE)
list
study_number="05"
library(matlabr)
library(data.table)
library(ggplot2)
library(dplyr)
library(tidyr)
library(cowplot)
library(magicfor)
library(stringi)
#study_number <- readline("Study number:");
attempt<- readline(prompt = "Fitting attempt number:");
sub_n<- readline(prompt = "Subject number:");
subject_folder<-gsub(" ","",paste("C:\\Users\\User\\Desktop\\unreal_psychophysics\\unreal_",study_number,"\\sub_",sub_n))
setwd("C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas")
load("psy_paths.rda")
paths<-psy_paths(subject_folder,attempt,sub_n)
subject_folder<-paths[1]
psychophysics_folder<-paths[2]
output_matlab<-paths[3]
unreal_random_temps<-paths[4]
results_folder<-paths[5]
unreal_input_folder<- paths[6]
rda_folder<-paths[7]
#readline(prompt = "Subject folder:");
repeat_number<-as.numeric(attempt)-1;
setwd(subject_folder)
#load the answers csv of the repeated staircases
repeat_file<-list.files(subject_folder, pattern=glob2rx("repeat*.csv"));
repeat_data<-read.csv(file=repeat_file)
repeat_file
#load the answers csv of the repeated staircases
repeat_file<-list.files(subject_folder, pattern=glob2rx("*repeat*.csv"));
repeat_data<-read.csv(file=repeat_file)
View(repeat_data)
unlink(repeat_file)
#load the previous attempt csv (there should be only one attempt file in the folder)
previous_attempt_file<-list.files(subject_folder, pattern=glob2rx("Answers*.csv"));
previous_attempt_data<-read.csv(file=previous_attempt_file)
unlink(previous_attempt_file)
previous_attempt_file
View(repeat_data)
repeat_data<- repeat_data %>% mutate(Attempt = as.numeric(attempt))
repeat_data[,repeat_data$Attempt]
repeat_data$Attempt
repeat_data$Attempt<-4
repeat_data$Attempt
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/repeat_jnd.R', echo=TRUE)
save(repeat_jnd, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\repeat_jnd.rda')
previous_attempt_file<-"Answers_Sub-003_Plan-JND_RunID-20221206-181405(2).csv"
library(stringi)
stri_sub(previous_attempt_file,1,42)
stri_sub(previous_attempt_file,1,-4)
stri_sub(previous_attempt_file,1,-5)
stri_sub(previous_attempt_file,1,5)
stri_sub(previous_attempt_file,1,-5)
previous_attempt_file<-stri_sub(previous_attempt_file,1,-5)
attempt<-2
#save the new data frame as an 'Answers' file
filename<-gsub(" ","",paste(previous_attempt_file,"_",as.character(attempt),"_.csv"))
filename
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/repeat_jnd.R', echo=TRUE)
save(repeat_jnd, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\repeat_jnd.rda')
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/repeat_jnd.R', echo=TRUE)
save(repeat_jnd, file = 'C:\\Users\\User\\Desktop\\unreal_psychophysics\\rdas\\repeat_jnd.rda')
source('C:/Users/User/Desktop/unreal_psychophysics/R functions/run_unreal_psy.R', echo=TRUE)
run_unreal_psy()
?between()
logistic$fitted.values<-c(0.1,0.05)
logistic_vec<-c(0.1,0.05)
sum(between(logistic_vec,left = 0.15,right = 0.85))
sum(between(logistic_vec,left = 0.15,right = 0.85,check=FASLE))
sum(between(logistic_vec,left = 0.15,right = 0.85,check=TRUE))
sum(between(logistic_vec,left = 0.15,right = 0.85))
library(tidyverse)
sum(between(logistic_vec,left = 0.15,right = 0.85))
logistic_vec<-c(0.16,0.1,0.89)
sum(between(logistic_vec,left = 0.15,right = 0.85))
logistic_vec
sum(between(logistic_vec,left = 0.15,right = 0.85))
logi_list<-list(0.16,0.8,0.89)
sum(between(logi_list,left = 0.15,right = 0.85))
